{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run the program\n",
    "To run this notebook, click kernel and run all. This should install the dependancies, perform the blackbox tests and start the GUI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Dependacies\n",
    " \n",
    "Installing required libaries using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in e:\\anaconda\\lib\\site-packages (4.5.5.62)\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in e:\\anaconda\\lib\\site-packages (from opencv-python) (1.22.3)\n",
      "Requirement already satisfied: mediapipe in e:\\anaconda\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: numpy in e:\\anaconda\\lib\\site-packages (from mediapipe) (1.22.3)\n",
      "Requirement already satisfied: matplotlib in e:\\anaconda\\lib\\site-packages (from mediapipe) (3.3.2)\n",
      "Requirement already satisfied: absl-py in e:\\anaconda\\lib\\site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in e:\\anaconda\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in e:\\anaconda\\lib\\site-packages (from mediapipe) (3.19.4)\n",
      "Requirement already satisfied: opencv-contrib-python in e:\\anaconda\\lib\\site-packages (from mediapipe) (4.5.5.62)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in e:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in e:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (2020.6.20)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (8.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in e:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: six in e:\\anaconda\\lib\\site-packages (from absl-py->mediapipe) (1.15.0)\n",
      "Requirement already satisfied: keyboard in e:\\anaconda\\lib\\site-packages (0.13.5)\n"
     ]
    }
   ],
   "source": [
    "#Un-comment if installing is required\n",
    "\n",
    "\n",
    "!pip install opencv-python\n",
    "!pip install mediapipe\n",
    "!pip install keyboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libaries\n",
    "Setting up the imports for the project and populating an array with the headers for the data about to be captured and a key press boolean for recording keyboard inputs for exporting the array to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import keyboard\n",
    "import time\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "\n",
    "csv = 'X_0, Y_0, X_1, Y_1, X_2, Y_2, X_3, Y_3, X_4, Y_4, X_5, Y_5, X_6, Y_6, X_7, Y_7, X_8, Y_8, X_9, Y_9, X_10, Y_10, X_11, Y_11, X_12, Y_12, X_13, Y_13, X_14, Y_14, X_15, Y_15, X_16, Y_16, X_17, Y_17, X_18, Y_18, X_19, Y_19, X_20, Y_20, Label\\n'\n",
    "\n",
    "reconstructed_model = keras.models.load_model(\"CNN_Hand_Model\", compile = True)\n",
    "\n",
    "keydown = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand Detector Class\n",
    "\n",
    "Creating a hand detector class for reusability. Handles using OpenCV model to location hand landmarks and return position information for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a hand detector class to allow this it be used for multiple projects\n",
    "\n",
    "class handDetector():\n",
    "    \n",
    "    def __init__(self, mode=False, Hands =2, Complexity=1, detectionConf=0.5, trackConf=0.5):\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.Hands = Hands\n",
    "        self.Complexity = Complexity\n",
    "        self.detectionConf = detectionConf\n",
    "        self.trackConf = trackConf\n",
    "        \n",
    "        self.mpHands = mp.solutions.hands\n",
    "        self.hands = self.mpHands.Hands(self.mode, self.Hands, self.Complexity, self.detectionConf, self.trackConf)\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "    def findHands(self, img, draw=True):\n",
    "        \n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imgRGB)\n",
    "\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mpDraw.draw_landmarks(img, handLms, \n",
    "                                               self.mpHands.HAND_CONNECTIONS)\n",
    "        return img\n",
    "    \n",
    "    def findPosition(self, img, handNo=0, draw=True):\n",
    "        \n",
    "        lmList = []\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            myHand = self.results.multi_hand_landmarks[handNo]\n",
    "            \n",
    "            for id, lm in enumerate(myHand.landmark):\n",
    "\n",
    "                    h ,w, c = img.shape\n",
    "                    cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "                    lmList.append([id, cx, cy])\n",
    "                    if draw:\n",
    "                        cv2.circle(img, (cx,cy), 15, (255, 0, 255), cv2.FILLED)\n",
    "                    \n",
    "        return lmList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prediction\n",
    "\n",
    "Function to handle data formating returning the model prediction in main loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def modelprediction(lmList):\n",
    "    buffer = [[]]\n",
    "    i = 0\n",
    "    for lm in lmList:\n",
    "        buffer[0].insert(i, float(lm[1]))\n",
    "        buffer[0].insert(i+1, float(lm[2]))\n",
    "        i += 2\n",
    "    \n",
    "    predictions = reconstructed_model.predict(buffer)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logical Finger Counter\n",
    "\n",
    "As basic hand signs are use, logic can be used to count fingers with very high accuracy. By doing this the model can be checked on all inputs to ensure the classifcation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberoffingers(lmList, tipIds):\n",
    "    fingers = []\n",
    "\n",
    "    # thumb\n",
    "    if lmList[tipIds[0]][1] > lmList[tipIds[0]-1][1]:\n",
    "        fingers.append(1)\n",
    "    else:\n",
    "        fingers.append(0)\n",
    "\n",
    "    # 4 fingers\n",
    "    for id in range(1,5):\n",
    "        if lmList[tipIds[id]][2] < lmList[tipIds[id]-2][2]:\n",
    "            fingers.append(1)\n",
    "        else:\n",
    "            fingers.append(0)\n",
    "\n",
    "    totalFingers = fingers.count(1)\n",
    "\n",
    "    return totalFingers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prediction\n",
    "This function is used for the blackbox testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelpredict(lmList):\n",
    "    predict = modelprediction(lmList)\n",
    "    predict = np.argmax(predict)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main loop function\n",
    "Function used for drawing the new image to GUI along with all relevant label updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frames():\n",
    "    \n",
    "    predict = []\n",
    "    success, img = cap.read()\n",
    "    img = detector.findHands(img)\n",
    "    lmList = detector.findPosition(img, draw=False)\n",
    "    tipIds = [ 4, 8, 12, 16, 20]\n",
    "    \n",
    "    if len(lmList) !=0:\n",
    "        totalFingers = numberoffingers(lmList, tipIds)\n",
    "        predict = modelpredict(lmList)\n",
    "        num_fingers.set(str(predict))\n",
    "\n",
    "        if predict == totalFingers:\n",
    "            #cv2.putText(img, str('Correct'),(45,375),cv2.FONT_HERSHEY_PLAIN,10,(0,255,0),25)\n",
    "            correct.set('Correct')\n",
    "        else:\n",
    "            #cv2.putText(img, str('Incorrect'),(45,375),cv2.FONT_HERSHEY_PLAIN,10,(255,0,0),25)\n",
    "            correct.set('Incorrect')\n",
    "      \n",
    "    # Get the latest frame and convert into Image\n",
    "    cv2image= cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(cv2image)\n",
    "    # Convert image to PhotoImage\n",
    "    imgtk = ImageTk.PhotoImage(image = img)\n",
    "    cam_label.imgtk = imgtk\n",
    "    cam_label.configure(image=imgtk)\n",
    "    # Repeat after an interval to capture continiously\n",
    "    cam_label.after(20, show_frames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black Box Tests\n",
    "Tests used to known data recording that represents the correct output for each number of held up fingers, this allows testing of both the model and logic function ability to correctly classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 5 Fingers Complete.\n"
     ]
    }
   ],
   "source": [
    "def test_5_finger():\n",
    "    lmList = [[0, 448, 407], [1, 489, 344], [2, 504, 270], [3, 507, 208], [4, 513, 158], [5, 411, 216], [6, 397, 145], [7, 383, 104], [8, 369, 70], [9, 369, 233], [10, 339, 164], [11, 317, 125], [12, 298, 95], [13, 338, 263], [14, 299, 206], [15, 273, 172], [16, 253, 143], [17, 317, 305], [18, 276, 274], [19, 249, 253], [20, 226, 230]]\n",
    "    tipIds = [ 4, 8, 12, 16, 20]\n",
    "    assert modelpredict(lmList) == 5\n",
    "    assert numberoffingers(lmList, tipIds) == 5\n",
    "    print(\"Test 5 Fingers Complete.\")\n",
    "    \n",
    "test_5_finger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 4 Fingers Complete.\n"
     ]
    }
   ],
   "source": [
    "def test_4_finger():\n",
    "    lmList = [[0, 292, 437], [1, 353, 393], [2, 381, 326], [3, 398, 267], [4, 426, 231], [5, 321, 252], [6, 325, 183], [7, 325, 141], [8, 324, 103], [9, 279, 256], [10, 276, 184], [11, 273, 140], [12, 270, 102], [13, 244, 280], [14, 209, 218], [15, 187, 181], [16, 171, 145], [17, 216, 319], [18, 194, 291], [19, 204, 314], [20, 220, 336]]\n",
    "    tipIds = [ 4, 8, 12, 16, 20]\n",
    "    assert modelpredict(lmList) == 4\n",
    "    assert numberoffingers(lmList, tipIds) == 4\n",
    "    print(\"Test 4 Fingers Complete.\")\n",
    "    \n",
    "test_4_finger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 3 Fingers Complete.\n"
     ]
    }
   ],
   "source": [
    "def test_3_finger():\n",
    "    lmList = [[0, 290, 448], [1, 350, 405], [2, 384, 339], [3, 420, 292], [4, 459, 267], [5, 327, 259], [6, 344, 187], [7, 353, 141], [8, 357, 101], [9, 281, 260], [10, 272, 183], [11, 263, 130], [12, 254, 86], [13, 244, 284], [14, 209, 250], [15, 227, 305], [16, 245, 341], [17, 213, 320], [18, 186, 307], [19, 204, 342], [20, 226, 366]]\n",
    "    tipIds = [ 4, 8, 12, 16, 20]\n",
    "    assert modelpredict(lmList) == 3\n",
    "    assert numberoffingers(lmList, tipIds) == 3\n",
    "    print(\"Test 3 Fingers Complete.\")\n",
    "    \n",
    "test_3_finger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2 Fingers Complete.\n"
     ]
    }
   ],
   "source": [
    "def test_2_finger():\n",
    "    lmList = [[0, 330, 438], [1, 392, 394], [2, 435, 324], [3, 474, 269], [4, 519, 239], [5, 362, 234], [6, 370, 158], [7, 369, 106], [8, 368, 65], [9, 313, 245], [10, 281, 205], [11, 288, 268], [12, 303, 309], [13, 270, 267], [14, 236, 244], [15, 256, 300], [16, 276, 326], [17, 236, 297], [18, 207, 277], [19, 227, 315], [20, 251, 333]]\n",
    "    tipIds = [ 4, 8, 12, 16, 20]\n",
    "    assert modelpredict(lmList) == 2\n",
    "    assert numberoffingers(lmList, tipIds) == 2\n",
    "    print(\"Test 2 Fingers Complete.\")\n",
    "    \n",
    "test_2_finger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 Fingers Complete.\n"
     ]
    }
   ],
   "source": [
    "def test_1_finger():\n",
    "    lmList = [[0, 353, 367], [1, 403, 321], [2, 443, 261], [3, 489, 212], [4, 540, 199], [5, 388, 174], [6, 355, 171], [7, 366, 222], [8, 388, 214], [9, 338, 186], [10, 311, 174], [11, 328, 235], [12, 347, 225], [13, 294, 202], [14, 268, 183], [15, 287, 238], [16, 312, 232], [17, 257, 219], [18, 236, 207], [19, 251, 242], [20, 273, 245]]\n",
    "    tipIds = [ 4, 8, 12, 16, 20]\n",
    "    assert modelpredict(lmList) == 1\n",
    "    assert numberoffingers(lmList, tipIds) == 1\n",
    "    print(\"Test 1 Fingers Complete.\")\n",
    "    \n",
    "test_1_finger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0 Fingers Complete.\n"
     ]
    }
   ],
   "source": [
    "def test_0_finger():\n",
    "    lmList = [[0, 447, 324], [1, 489, 281], [2, 518, 214], [3, 494, 174], [4, 447, 181], [5, 451, 160], [6, 446, 122], [7, 463, 174], [8, 467, 188], [9, 410, 170], [10, 400, 132], [11, 421, 187], [12, 421, 196], [13, 373, 190], [14, 360, 154], [15, 386, 201], [16, 389, 210], [17, 334, 216], [18, 330, 189], [19, 352, 219], [20, 357, 230]]\n",
    "    tipIds = [ 4, 8, 12, 16, 20]\n",
    "    assert modelpredict(lmList) == 0\n",
    "    assert numberoffingers(lmList, tipIds) == 0\n",
    "    print(\"Test 0 Fingers Complete.\")\n",
    "    \n",
    "test_0_finger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Method\n",
    "Initilised the camera source, creating the GUI variables and running GUI loop for the program to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wCam, hCam = 640, 480\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, wCam)\n",
    "cap.set(4, hCam)\n",
    "    \n",
    "detector = handDetector(detectionConf=0.75)\n",
    "\n",
    "# Create an instance of TKinter Window or frame\n",
    "#gui creation\n",
    "win = Tk()\n",
    "\n",
    "# Set the size of the window, stop resize, rename title\n",
    "win.geometry(\"850x480\")\n",
    "win.resizable(False, False)\n",
    "win.title('AI and Robotics - John Robson')\n",
    "\n",
    "#Declaring changing variables\n",
    "num_fingers = StringVar()\n",
    "correct = StringVar()\n",
    "\n",
    "# Create a Label to capture the Video frames and labal changes\n",
    "finger_title = Label(win, text=\"Number of fingers predicted\")\n",
    "finger_title.place(x=660, y=10)\n",
    "\n",
    "finger_label = Label(win, textvariable=num_fingers)\n",
    "finger_label.place(x=720, y=30)\n",
    "\n",
    "correct_title = Label(win, text=\"The classification was:\")\n",
    "correct_title.place(x=720, y=70, anchor=CENTER)\n",
    "\n",
    "correct_label = Label(win, textvariable=correct) \n",
    "correct_label.place(x=720, y=100, anchor=CENTER)\n",
    "\n",
    "cam_label = Label(win)\n",
    "cam_label.grid(row=0, column=0)\n",
    "\n",
    "# Define function to show frame\n",
    "#main\n",
    "\n",
    "show_frames()\n",
    "win.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
