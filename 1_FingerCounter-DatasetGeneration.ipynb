{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run the program\n",
    "To run this notebook, click kernel and run all. This should install the dependancies, start a camera feed which will save data on hand features it is given and will wait for you to press '.' on the notebook to save the data to a CSV file which will be used in the 'Building a model' notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependacies\n",
    "\n",
    "Installing required libaries using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in e:\\anaconda\\lib\\site-packages (4.5.5.62)\n",
      "Requirement already satisfied: numpy>=1.17.3; python_version >= \"3.8\" in e:\\anaconda\\lib\\site-packages (from opencv-python) (1.22.3)\n",
      "Requirement already satisfied: mediapipe in e:\\anaconda\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: opencv-contrib-python in e:\\anaconda\\lib\\site-packages (from mediapipe) (4.5.5.62)\n",
      "Requirement already satisfied: matplotlib in e:\\anaconda\\lib\\site-packages (from mediapipe) (3.3.2)\n",
      "Requirement already satisfied: numpy in e:\\anaconda\\lib\\site-packages (from mediapipe) (1.22.3)\n",
      "Requirement already satisfied: attrs>=19.1.0 in e:\\anaconda\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in e:\\anaconda\\lib\\site-packages (from mediapipe) (3.19.4)\n",
      "Requirement already satisfied: absl-py in e:\\anaconda\\lib\\site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in e:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (8.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in e:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (2.8.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in e:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (2020.6.20)\n",
      "Requirement already satisfied: six in e:\\anaconda\\lib\\site-packages (from absl-py->mediapipe) (1.15.0)\n",
      "Requirement already satisfied: keyboard in e:\\anaconda\\lib\\site-packages (0.13.5)\n"
     ]
    }
   ],
   "source": [
    "#Un-comment if installing is required\n",
    "\n",
    "!pip install opencv-python\n",
    "!pip install mediapipe\n",
    "!pip install keyboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libaries\n",
    "Setting up the imports for the project and populating an array with the headers for the data about to be captured and a key press boolean for recording keyboard inputs for exporting the array to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required libaries\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import keyboard\n",
    "import time\n",
    "\n",
    "csv = 'X_0, Y_0, X_1, Y_1, X_2, Y_2, X_3, Y_3, X_4, Y_4, X_5, Y_5, X_6, Y_6, X_7, Y_7, X_8, Y_8, X_9, Y_9, X_10, Y_10, X_11, Y_11, X_12, Y_12, X_13, Y_13, X_14, Y_14, X_15, Y_15, X_16, Y_16, X_17, Y_17, X_18, Y_18, X_19, Y_19, X_20, Y_20, Label\\n'\n",
    "\n",
    "keydown = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand Detector Class\n",
    "\n",
    "Creating a hand detector class for reusability. Handles using OpenCV model to location hand landmarks and return position information for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a hand detector class to allow this it be used for multiple projects\n",
    "\n",
    "class handDetector():\n",
    "    \n",
    "    def __init__(self, mode=False, Hands =2, Complexity=1, detectionConf=0.5, trackConf=0.5):\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.Hands = Hands\n",
    "        self.Complexity = Complexity\n",
    "        self.detectionConf = detectionConf\n",
    "        self.trackConf = trackConf\n",
    "        \n",
    "        self.mpHands = mp.solutions.hands\n",
    "        self.hands = self.mpHands.Hands(self.mode, self.Hands, self.Complexity, self.detectionConf, self.trackConf)\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "    def findHands(self, img, draw=True):\n",
    "        \n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imgRGB)\n",
    "\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mpDraw.draw_landmarks(img, handLms, \n",
    "                                               self.mpHands.HAND_CONNECTIONS)\n",
    "        return img\n",
    "    \n",
    "    def findPosition(self, img, handNo=0, draw=True):\n",
    "        \n",
    "        lmList = []\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            myHand = self.results.multi_hand_landmarks[handNo]\n",
    "            \n",
    "            for id, lm in enumerate(myHand.landmark):\n",
    "\n",
    "                    h ,w, c = img.shape\n",
    "                    cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "                    lmList.append([id, cx, cy])\n",
    "                    if draw:\n",
    "                        cv2.circle(img, (cx,cy), 15, (250, 0, 250), cv2.FILLED)\n",
    "                    \n",
    "        return lmList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic Classification for Data Logging\n",
    "Using logical classification to create a dataset for later model training, this is purely used for creating data quickly with accurate data labeling. Also used for drawing the logic's classification to the webcam image as a overlay to ensure it is working correctly when in operation. On each loop, the method checks to see if the '.' key has been pressed on the notebook to indicate that the data should be exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def finger_counter():\n",
    "    \n",
    "    global keydown\n",
    "\n",
    "    wCam, hCam = 640, 480\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3, wCam)\n",
    "    cap.set(4, hCam)\n",
    "\n",
    "    folderPath = \"digitimg\"\n",
    "    myList = os.listdir(folderPath)\n",
    "\n",
    "    print(myList)\n",
    "\n",
    "\n",
    "    overlayList = []\n",
    "    for imPath in myList:\n",
    "        image = cv2.imread(f'{folderPath}/{imPath}')\n",
    "        overlayList.append(image)\n",
    "\n",
    "    print(len(overlayList))\n",
    "    pTime = 0\n",
    "\n",
    "\n",
    "    detector = handDetector(detectionConf=0.75)\n",
    "\n",
    "    tipIds = [ 4, 8, 12, 16, 20]\n",
    "\n",
    "\n",
    "    while True:\n",
    "\n",
    "        success, img = cap.read()\n",
    "        img = detector.findHands(img)\n",
    "        lmList = detector.findPosition(img, draw=False)\n",
    "\n",
    "        if len(lmList) !=0:\n",
    "            fingers = []\n",
    "\n",
    "            # thumb\n",
    "            if lmList[tipIds[0]][1] > lmList[tipIds[0]-1][1]:\n",
    "                fingers.append(1)\n",
    "            else:\n",
    "                fingers.append(0)\n",
    "\n",
    "            # 4 fingers\n",
    "            for id in range(1,5):\n",
    "                if lmList[tipIds[id]][2] < lmList[tipIds[id]-2][2]:\n",
    "                    fingers.append(1)\n",
    "                else:\n",
    "                    fingers.append(0)\n",
    "\n",
    "            totalFingers = fingers.count(1)\n",
    "\n",
    "            h, w, c = overlayList[totalFingers-1].shape\n",
    "            img[0:h, 0:w] = overlayList[totalFingers-1]\n",
    "\n",
    "            cv2.rectangle(img, (29,255),(170,425),(0,255,0), cv2.FILLED)\n",
    "            cv2.putText(img, str(totalFingers),(45,375),cv2.FONT_HERSHEY_PLAIN,10,(255,0,0),25)\n",
    "\n",
    "        cTime = time.time()\n",
    "        fps = 1/(cTime - pTime)\n",
    "        pTime = cTime\n",
    "\n",
    "\n",
    "\n",
    "        if len(lmList)!=0:\n",
    "            storelmtomemory(lmList, totalFingers)\n",
    "        \n",
    "        try:  # used try so that if user pressed other than the given key error will not be shown\n",
    "            if keyboard.is_pressed('.'):  # if key '.' is pressed \n",
    "                \n",
    "                if keydown == False:\n",
    "                    keydown = True\n",
    "                    writememorytocsv()\n",
    "                    time.sleep(0.5)\n",
    "                    keydown = False\n",
    "        except:\n",
    "            x = 1\n",
    "\n",
    "\n",
    "        cv2.putText(img, f'FPS: {int(fps)}', (400, 70), cv2.FONT_HERSHEY_PLAIN, 3, (255,0,0), 3)\n",
    "\n",
    "        cv2.imshow(\"Image\", img)\n",
    "        cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Data\n",
    "storelmtomemory - Used to pass each data line to a buffer array to hold all the data captured in the session\n",
    "\n",
    "writememorytocsv - Takes the data held by 'storelmtomemory' and writes this data to a CSV file to be used in the 'Building a model' Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storelmtomemory(lmList, totalFingers):\n",
    "    global csv\n",
    "    for lm in lmList:\n",
    "        csv += f'{lm[1]},{lm[2]},'\n",
    "        \n",
    "    csv += f'{totalFingers}\\n'\n",
    "    \n",
    "def  writememorytocsv():\n",
    "    dt = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    f = open(f'handdata_{dt}.csv', \"a\")\n",
    "    f.write(csv)\n",
    "    f.close()\n",
    "    print('Wrote to file.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Method\n",
    "Finger_counter creates a while loop camera feed that only adds to the buffer array when a hand is detected. Data will continue to be recorded into this buffer until the notepad detects the '.' key pressed, which will then write the buffer to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.jpg', '2.jpg', '3.jpg', '4.jpg', '5.jpg', '6.jpg']\n",
      "6\n",
      "Wrote to file.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    finger_counter()\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted')\n",
    "try:\n",
    "    sys.exit(0)\n",
    "except SystemExit:\n",
    "    os._exit(0)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
